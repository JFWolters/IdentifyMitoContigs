##V7 update
#Heavily modified to work on output from new pipeline in which real GFF3 files are made for annotations
#Now takes in genbank format to easily parse annotations
#Removed all filtering to avoid introduced biases
###V7.1 update
#the genbank list file is expected to follow format [species].gb_list_file.txt
#outFileName is now formatted as [species].annotation_summary.tab
###V7.2 update
#added os functionality to handle extracting base file name of [species].gb_list_file.txt
#[species].gb_list_file.txt is assumed to have full path to list
##V7.3 update
#the file naming scheme for annotation_summary.tab screwed up if species had a "." in it
#[species] was added back as input to circumvent this issue
##V7.4 update
#genes_found is now a true column with gene names being comma delimited
#v7.5
#renamed 1st output column to Contig


##V6 update
#unclear? didn't log changes

###V5 update
#Added length tracking and exclusion of contigs under a size cutoff

#V4 update
#contigs that dont contain at least 1 CDS (excluding VAR1) are filtered out

#V3 update
#added filtering to remove annotations when a contig does not meet a size criteria
#in this implementation if only one gene is present the contig must be less than 10 kb in length
#this should filter out invalid single gene annotations on large nuclear contigs

#V2 update
#instead takes in a GFF file
#Generated by the MFAnnot2GFF.2.py script (v2 is required to handle ambiguous rnl annotations)

#Takes in annotations and target gene names
#Summarize the presence of a given set of target sequences from a separate file

import sys
import os
from Bio import SeqIO


def processInputs():

    targets_file = sys.argv[1]
    
    gb_list_file = sys.argv[2]
    
    species = sys.argv[3]
    
    return targets_file , gb_list_file , species
    
def readTargets(targets_file):

    tfile = open(targets_file,"r")
    
    lines = tfile.readlines()
    
    targets = []
    
    for line in lines:
        
        name = line.rstrip('\n')
        
        targets.append(name)
        
    tfile.close()
    
    return targets

def readGenbank(inFileName):
    # print(inFileName)
    
    records = []
    
    inFile = open(inFileName,"r")
    lines=inFile.readlines()
    inFile.close()
    # print(lines)
    lines = [line.rstrip('\n') for line in lines]
    
    for line in lines:
        records.extend(list(SeqIO.parse(line,"genbank")))
    # print(records)
    return records

def identifyTargets(targets, records):
    
    out = [] #list of gene sets
    
    for record in records:
        print(record.id)
        gene_names = []
        
        for feat in record.features:
            if feat.type == "CDS":
                #Note, I have seen one case where for genes where there are duplicates, there is no gene tag in one copy
                #for summary purposes this is irrelevant because the other copy gets counted
                #adding in an exception for this scenario to skip the problem case
                try:
                    gene_name = feat.qualifiers["gene"][0]
                    
                    gene_names.append(gene_name)
                except KeyError:
                    continue #skip genes that are missing a gene tag in the genbank file, see comments above on probable causes
        genes = filterGenes(gene_names, targets) #gene set (list of genes)
        
        out.append(genes)
        
    return out
    
def filterGenes(gene_names,targets):
    
    gene_names = set(gene_names)
    
    out = []
    
    for gene in gene_names:
        if gene in targets:
            out.append(gene)
        elif "_" in gene:
            base = gene.split("_")[0]
            if base in targets:
                out.append(gene)
    
    return out
    
def writeOutput(species, gene_sets, records):
    
    
    outFileName = species + ".annotation_summary.tab"

    outFile = open(outFileName,"w")
    
    header = "Contig\tContig_Length\tNum_Genes_Found\tGenes_Found\n"
    
    outFile.write(header)
    
    for i in range(len(gene_sets)):
    
        out_line = records[i].id + "\t" + str(len(records[i].seq)) + "\t"
        
        num_hits = len(condenseDuplicateGenes(gene_sets[i]))
        
        out_line = out_line + str(num_hits) + "\t"
        
        if len(gene_sets[i]) == 0:
            out_line = out_line + "None\n"
        
        for name in gene_sets[i]:
        
            out_line = out_line + name + ","
        if out_line.endswith(","):
            out_line = out_line.rstrip(",") + "\n"
        
        outFile.write(out_line)
        
    outFile.close()
    
    print(outFileName, "created")
    
def condenseDuplicateGenes(genes):
    
    simplified = [gene.split("_")[0] for gene in genes]
    
    simplified = set(simplified)
    
    return simplified

def main():

    targets_file , gb_list_file , species = processInputs()
    
    targets = readTargets(targets_file)
    
    records = readGenbank(gb_list_file)
    
    found_genes = identifyTargets(targets, records)
    
    writeOutput(species,found_genes, records)
    
main()
